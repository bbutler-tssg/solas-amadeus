{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# avro2neo: Loading avro-format transaction trees into neo4j and hence into other tools\n",
    "\n",
    "## Introduction\n",
    "\n",
    "ESI data is processed by `Cormel` into *transaction trees* with the following\n",
    "structure:\n",
    "\n",
    "* Cormel defines 5 \"segments\" in all: A, E, H, T and U, which store data\n",
    "pertaining to transaction trees.\n",
    "* The common features (across all entities of the transaction tree) are stored\n",
    "in a `U` segment for each transaction tree, which acts as the root of the tree.\n",
    "* The `U` node is connected to a single `T` node, which is the transaction that\n",
    "spawns the other transactions in the tree.\n",
    "* Each transaction `T` node can have 0 or more child transactions (`T` nodes).\n",
    "* The leaf nodes can be `T` nodes, or alternatively hop (`H`) nodes, `A` or `E`\n",
    "nodes.\n",
    "* The `A` and `E` nodes often have blank properties and/or default data, and\n",
    "so are loaded into neo4j but are not used for further analysis. They appear to\n",
    "be descriptive and are shared between transaction trees.\n",
    "\n",
    "Each Cormel segment is associated with a standard list of fields, hence it is\n",
    "equivalent to a table in a relational database, or a node in a property graph.\n",
    "\n",
    "Although transaction trees have a natural mapping into graph data structures,\n",
    "this aspect of their nature has not been explored in Amadeus. The research\n",
    "hypothesis is that transaction trees can be classified into two categories,\n",
    "depending on whether they are associated with *successful* or *unsuccessful*\n",
    "outcomes.\n",
    "\n",
    "Note that *success* and *failure* have specific meanings in this context. For\n",
    "example, a customer could decide to abandon a search, or even a booking, before\n",
    "completing all steps. Because the customer made the decision, Amadeus\n",
    "infrastructure was not at fault, and the incomplete transaction tree does not\n",
    "represent a problem for the Amadeus devops team to fix[^1]. Another scenario\n",
    "would be that a network link failure occurred, in which case the service\n",
    "response never arrived, so the customer had no choice and was unable to proceed\n",
    "with the transaction. As seen by the customer, the system became unresponsive,\n",
    "or even provided an error message of the form \"The system is currently\n",
    "unavailable.  Please try again later.\" Neither of these represents a\n",
    "*successful* outcome. Even worse, such problems are likely to recur, and to\n",
    "affect other customers. Hence they need to be addressed as soon as possible.\n",
    "\n",
    "[^1]: Perhaps the Customer Experience team might be interested in analysing\n",
    "transactions abandoned by customers, as there might be ways of improving the\n",
    "customer experience with the intention of increasing the completion rate of\n",
    "transactions. However, such offline analysis is outside the scope of the\n",
    "present study.\n",
    "\n",
    "The research hypothesis is that there are *structural* and/or *property*\n",
    "differences between successful and unsuccessful transaction trees. Furthermore,\n",
    "it might even be possible to suggest some queries that could be used to derive\n",
    "the root cause of *correlated* problems.\n",
    "\n",
    "One possible structural difference might include highly unbalanced trees,\n",
    "reflecting the fact that, if a particular edge in the tree failed, the\n",
    "redundancy built into the Amadeus services infrastructure is such that other\n",
    "parts of the transaction might succeed (and generate lots of activity in the\n",
    "logs, hence segments in the Cormel transaction tree) although the overall\n",
    "transaction might fail.\n",
    "\n",
    "Property differences could be subtle and might be more useful for root cause\n",
    "determination. For example, the transaction might invoke a service that was\n",
    "recently updated, or be directed to an endpoint that is struggling to meet\n",
    "demand. Such property data is stored in the segment records. (Graph) database\n",
    "queries might help to find common property settings across problematic\n",
    "transaction trees.\n",
    "\n",
    "## The processing pipeline\n",
    "\n",
    "### Cormel format to Avro\n",
    "\n",
    "The Cormel system takes data from the logs and generates the transaction trees.\n",
    "This data is then serialised in [Avro](https://avro.apache.org/) format and\n",
    "stored efficiently in (binary) data files. A single example file was provided\n",
    "for development purposes and placed in the `avro2neo/input` directory. In Avro\n",
    "format it occupies 13.9MB and contains 24,499 transaction tree records, as\n",
    "counted by the [avrocount](https://github.com/jwoschitz/avrocount) command-line\n",
    "tool:\n",
    "\n",
    "    java -jar ~/tools/avro/avrocount-0.3.0.jar\\\n",
    "      input/par_U170504_010000_S170504_005800_D60_lgcaa101_20205_0000.gz.avro\\\n",
    "      2> /dev/null\n",
    "\n",
    "\n",
    "### Cormel Avro format to Cormel JSON format\n",
    "\n",
    "The Avro format, being binary, is not suitable for inspecting the data.\n",
    "However, it can be converted easily to JSON format. First, we use the\n",
    "[avro-tools](https://avro.apache.org/) tool to derive the Cormel Avro schema\n",
    "`cormel.avsc`:\n",
    "\n",
    "    java -jar ~/tools/avro/avro-tools-1.8.2.jar getschema\\\n",
    "      input/par_U170504_010000_S170504_005800_D60_lgcaa101_20205_0000.gz.avro\\\n",
    "      > cormel.avsc\n",
    "\n",
    "We can now use [avro-tools](https://avro.apache.org/) to generate the JSON format,\n",
    "using the `--pretty` option, otherwise the generated JSON lines are extremely long\n",
    "and hard to read:\n",
    "\n",
    "    java -jar ~/tools/avro/avro-tools-1.8.2.jar tojson --pretty\\\n",
    "      input/par_U170504_010000_S170504_005800_D60_lgcaa101_20205_0000.gz.avro\\\n",
    "      > input/converted.json\n",
    "\n",
    "For reference, the resulting `input/converted.json` occupies 395.2MB and has\n",
    "14,470,577 lines of text.\n",
    "\n",
    "Once the data is in Cormel Avro format, it is possible to investigate it and\n",
    "generate subsets.\n",
    "\n",
    "\n",
    "\n",
    "### Cormel Avro format to neo4j\n",
    "\n",
    "[Neo4j](https://neo4j.com/) claims to be the world's leading graph database\n",
    "platform. It is relatively mature and so offers many tools, particularly in its\n",
    "[APOC](https://guides.neo4j.com/apoc) extension suite, for graph data analysis\n",
    "and other advanced operations. Thus it was the obvious graph platform choice.\n",
    "\n",
    "#### Parsing and mapping from Avro to Neo4j\n",
    "\n",
    "To upload the data into Neo4j, it is necessary to parse the Cormel data\n",
    "hierarchy for each transaction tree, and to map each entity into a Neo4j node,\n",
    "with the edges in the transaction tree being mapped to Neo4j relationships. The\n",
    "data fields in each Cormel segment are mapped to properties in the associated\n",
    "Neo4j node.  The node types (`A`, `E`, `H`, `T` and `U`) become Neo4j node\n",
    "*labels*, and are also added as an extra node property for convenience when\n",
    "creating queries.\n",
    "\n",
    "#### Uniqueness constraints\n",
    "As with any database, it is necessary to define constraints so that duplicate\n",
    "nodes and relationships are not generated when parsing the transaction trees. For the\n",
    "legacy indexes in Neo4j 1.x, it was the developer's responsibility to write the\n",
    "business logic to enforce the constraints to prevent entity duplication.  Since\n",
    "Neo4j version 2.0, database-level index operations have become available and\n",
    "much of this logic can be defined declaratively, at the database level, as\n",
    "would be common in RDBMS. For Neo4j Enterprise customers, uniqueness\n",
    "constraints can be defined in terms of a combination of property fields, but\n",
    "each constraint in Neo4j Community Edition is limited to a single property field. In\n",
    "RDBMS terms, the distinction is between *simple* and *compound* indexes. As a\n",
    "workaround, we derived a key based on a concatenation of the properties in each\n",
    "node, stored it in the node as an additional property, and defined the\n",
    "uniqueness constraint in terms of this derived key.\n",
    "\n",
    "This workaround achieves the objective of guaranteeing uniqueness, but at the\n",
    "cost of doubling the space requirement for each node.\n",
    "\n",
    "#### Architecture and performance\n",
    "\n",
    "Initially, Neo4j was deployed as a service running in a docker container on the\n",
    "development laptop. This worked well, until we needed to deploy the latest\n",
    "version of APOC, and could not find a suitable container definition. We then\n",
    "switched to a local (in the sense of being installed into `~/tools`)\n",
    "installation of the Neo4j service.\n",
    "\n",
    "The upload application is written in Java and interacts with the Neo4j server\n",
    "by issuing parametrised cypher commands via the the Java database driver over\n",
    "Neo4j's `Bolt` binary protocol. Generally, the parameters define the node\n",
    "properties (key-value pairs) containing the data that needs to be uploaded from\n",
    "the Cormel segments comprising the transaction tree.\n",
    "\n",
    "The Cormel upload runs in its own JVM, outside the JVM used by Neo4j, but\n",
    "sharing resources such as the laptop's CPU, memory and disk. Therefore\n",
    "efficient use of these resources is a priority.\n",
    "\n",
    "Initial upload runs had poor performance. Switching to a more powerful laptop\n",
    "(with a Xeon server-class processor and 64GB of memory) brought little\n",
    "improvement.  By instrumenting the code, we discovered that performance dropped\n",
    "as more data was uploaded: transaction tree load times started at about 14\n",
    "seconds and steadily increased as more transaction trees were added to the\n",
    "database. Thus a full load (of approximately 25K transaction trees) would take\n",
    "days to complete.  CPU activity was very high so the laptop fan needed to work\n",
    "hard to keep the laptop cool. Thus we stopped the uploads as soon as it became\n",
    "apparent they were making slow progress.\n",
    "\n",
    "Further analysis indicated that initial versions of the upload application did\n",
    "not rebuild the Neo4j indexes after refreshing the database and so were unable\n",
    "to benefit from these indexes when enforcing the constraints, resulting in the\n",
    "graph database equivalent of \"full table scans\".  When this problem was fixed,\n",
    "the overall run time dropped to less than 7 minutes for the full set of\n",
    "transaction trees.\n",
    "\n",
    "Resource usage remained quite high, so more flexible transaction handling was\n",
    "introduced.  Initial versions opened up a single session for each file upload,\n",
    "which had the effect of beginning a transaction which was closed when the\n",
    "session closed after all the Cormel data in that file had been processed.\n",
    "However, Neo4j allows developers to create transactions explicitly. It is even\n",
    "possible, though discouraged in the documentation, to insert\n",
    "`beginTransaction()` and corresponding `success()` (commit) and `close()`\n",
    "method calls in the code. This fine degree of transaction control was added,\n",
    "shaving about 20 seconds off the overall run time, and reducing the resource\n",
    "usage (as seen from the output of the `top` command).\n",
    "\n",
    "Timing data for each run can be found in `output/timings/yyyymmdd_HHMMSS.txt`,\n",
    "where `yyyymmdd_HHMMSS` represents a typical timestamp for when the run\n",
    "started. Timing data can be plotted using the `octave` function\n",
    "`script/plotTimings.m` as follows:\n",
    "\n",
    "    echo \"cd script; plotTimings(\\\"../output/timings/20170802_153002.txt\\\")\"\\\n",
    "      | octave -qf 2> /dev/null\n",
    "\n",
    "where the resulting plot can be found in `output/timings/20170802_153002.pdf`\n",
    "which can be viewed in Figure 1 below. For convenience, the PDF can be cropped\n",
    "as follows:\n",
    "\n",
    "    pdfcrop --margins 5 output/timings/20170802_153002.pdf\\\n",
    "      graphics/20170802_153002-CROPPED.pdf\n",
    "\n",
    "and converted to PNG (for insertion into MS documents on MS Windows; PDF gives better results\n",
    "(because it is a vector format) in both LaTeX and LibreOffice documents and MS documents on MacOS) using\n",
    "\n",
    "    pdftoppm -f 1 -singlefile -png graphics/20170802_153002-CROPPED.pdf\\\n",
    "      graphics/20170802_153002-CROPPED\n",
    "\n",
    "The resulting plot can be viewed in Figure 1 below.\n",
    "\n",
    "For convenience, it is possible to recreate this and other PNG files using\n",
    "\n",
    "    script/pdf2png.sh 1024\n",
    "\n",
    "where `1024` in this example represents the desired resolution, in pixels, of\n",
    "the longest side of the image. Note that `script/pdf2png.sh` is designed not to\n",
    "overwrite existing PNG files in the set it generates.\n",
    "\n",
    "\n",
    "![Figure 1: Timing data for uploading Cormel records to neo4j.](img/20170802_153002-CROPPED.png)\n",
    "\n",
    "#### The upload application\n",
    "\n",
    "The upload application has many transitive dependencies and so was built using\n",
    "maven.  It is run as a command line application with two arguments: the\n",
    "location of the Avro input file, and a string (which defaults to `partial`)\n",
    "indicating whether this is a full (all records) or partial (just a subset of\n",
    "the records) upload.  If it is a partial load,\n",
    "\n",
    "* the time taken to load each transaction tree is reported on `stdout` and sent to a timings file.\n",
    "* there is just one `transaction` per `session`\n",
    "\n",
    "For a `full` upload, progress reporting frequency is reduced (once every 500\n",
    "transaction tree uploads, say) and there are multiple `transaction`s per\n",
    "`session` (a transaction is committed, closed and a new one opened after 2500\n",
    "transactions trees have been uploaded, say).\n",
    "\n",
    "Upload runs have the following form:\n",
    "\n",
    "    script/uploadCormelAvroToNeo4j.sh\\\n",
    "      input/par_U170504_010000_S170504_005800_D60_lgcaa101_20205_0000.gz.avro\\\n",
    "      full\n",
    "\n",
    "or\n",
    "\n",
    "    script/uploadCormelAvroToNeo4j.sh input/sample.avro partial\n",
    "\n",
    "This bash script stops the Neo4j database if it is running, resets the database\n",
    "and restarts it before invoking the Java application with the appropriate\n",
    "arguments. The Java application does the work.\n",
    "\n",
    "#### Analysis options in Neo4j\n",
    "\n",
    "Neo4j, via its APOC extension package, offers the following graph analysis algorithms:\n",
    "\n",
    "* Closeness centrality: `apoc.algo.closeness(...)`\n",
    "* Betweenness Centrality: `apoc.algo.betweenness(...)`\n",
    "* PageRank: `apoc.algo.pageRankWithConfig(...)` and `apoc.algo.pageRank(...)`\n",
    "\n",
    "Because of the structure of the graph, the results are not particularly interesting.\n",
    "However, if the transaction trees were classified into \"successful\" and \"failed\"\n",
    "categories, it might be possible to use such per-node scores to suggest interesting\n",
    "discriminating features.\n",
    "\n",
    "#### Visualisation and analysis options\n",
    "\n",
    "Neo4j provides a basic visualisation using a force-directed layout. While this is\n",
    "adequate for development and testing purposes, it is difficult to see the\n",
    "underlying \"forest of trees\" structure of the graph.\n",
    "\n",
    "[yEd](https://www.yworks.com/products/yed) and [Gephi](https://gephi.org) are\n",
    "attractive tools for visualising graphs. The former is more of a business\n",
    "diagram drawing tool with particularly good support for graph-based diagrams.\n",
    "The latter is intended more for visualising graphs in their own right; it also\n",
    "has extensive graph metric calculations.\n",
    "\n",
    "There are potentially ways to stream Neo4j data to Gephi for plotting, but no\n",
    "equivalent support is offered for yEd. Therefore, the approach that offers the\n",
    "most flexibility is to serialise Neo4j data to a common format. In that regard,\n",
    "graphml is the most attractive format, as\n",
    "\n",
    "1. It can be uploaded into both yEd and Gephi\n",
    "2. An APOC procedure exists to export Neo4j data in graphml format.\n",
    "\n",
    "The main downside is that graphml is a verbose XML-based format and hence\n",
    "results in relatively large files.\n",
    "\n",
    "#### Exporting Node4j data to graphml\n",
    "\n",
    "The following command can be used to export the Neo4j database in graphml\n",
    "format:\n",
    "\n",
    "    script/exportNeo4jToGraphml.sh script/exportNeo4jToGraphml.cql\\\n",
    "      script/full.cql output/graphml/full.graphml\n",
    "\n",
    "The problem with this procedure is that it does not scale well with the size of\n",
    "the database and has never run to completion in any test so far. However, in\n",
    "that regard, it would be impossible to interpret a visualisation of 24,499\n",
    "transaction trees, so it makes sense to derive a random sample of such\n",
    "transaction trees, and to export this to graphml instead.\n",
    "\n",
    "[This stackexchange question](https://stackoverflow.com/a/45469605/1988855)\n",
    "indicates two ways to extract a random subforest of the full forest. Neo4j JVM\n",
    "memory management problems arose with both, even with the JVM memory limit\n",
    "setting in `neo4j.conf` increased to 4GB (from 512MB). A common error message\n",
    "was `GC limit exceeded` where `GC` is the JVM's Garbage Control process. Even\n",
    "when just the queries run, without attempting to serialise the query results to\n",
    "graphml, the problem persists. Therefore, an alternative approach was needed.\n",
    "\n",
    "There is a tool ([`ratatool`](https://github.com/spotify/ratatool)) that\n",
    "extracts a sample of records from Avro files. A bash script was written to\n",
    "provide a more convenient interface. An example invocation of this bash script\n",
    "is:\n",
    "\n",
    "    script/randomSampleFromAvro.sh -i\\\n",
    "      input/par_U170504_010000_S170504_005800_D60_lgcaa101_20205_0000.gz.avro\\\n",
    "      -o input/sample20.avro -n 20\n",
    "\n",
    "This sample data can be uploaded, replacing any existing Cormel data in the\n",
    "Neo4j database, using\n",
    "\n",
    "    script/uploadCormelAvroToNeo4j.sh input/sample20.avro partial\n",
    "\n",
    "This data can then be exported as graphml using either\n",
    "\n",
    "    script/exportNeo4jToGraphml.sh script/exportNeo4jToGraphml.cql\\\n",
    "      script/full.cql output/graphml/sample20.graphml\n",
    "\n",
    "or\n",
    "\n",
    "    script/exportNeo4jToGraphml.sh script/exportNeo4jToGraphml.cql\\\n",
    "      script/fullAPOC.cql output/graphml/sample20.graphml\n",
    "\n",
    "#### Importing the graphml export file into Gephi and yEd\n",
    "\n",
    "Both yEd and Gephi import the exported graphml files without complaint.\n",
    "However, there is some data loss. This is because the APOC graphml export\n",
    "function does not not \"register\" graphml `<key ..>` elements for each of the\n",
    "Neo4j node properties stored in graphml `<data ..>` elements. Consequently\n",
    "these `<data ..>` elements are dropped silently on import. The properties and\n",
    "their values provide vital context for each node, notably their Neo4j label\n",
    "(equivalently, their Cormel segment type) among others, so it is necessary to\n",
    "ensure that this data is protected from deletion on upload.\n",
    "\n",
    "A python script was written to add the missing elements, and also to add data\n",
    "that is interpreted by the importing application (yEd or Gephi) to display the\n",
    "node in colour. This type of additional data is application-specific (different\n",
    "XML attributes are used for the Neo4j properties in each `<key..>` definition\n",
    "format, and node colours are specified differently also), so two\n",
    "variants of extended graphml are needed (one for Gephi, one for yEd).\n",
    "\n",
    "    script/neo4jGraphmlToOtherGraphml.py output/graphml/sample20.graphml\\\n",
    "      output/graphml/sample20gephi.graphml gephi\n",
    "\n",
    "and\n",
    "\n",
    "    script/neo4jGraphmlToOtherGraphml.py output/graphml/sample20.graphml\\\n",
    "      output/graphml/sample20yed.graphml yed\n",
    "\n",
    "The files relevant to each application can be uploaded without data loss, and\n",
    "the nodes will be coloured according to their Cormel segment (equivalently,\n",
    "Neo4j label).\n",
    "\n",
    "#### Displaying the transaction trees in Gephi and yEd\n",
    "\n",
    "Several different layouts can be used to display transaction trees in both\n",
    "Gephi and yEd. Gephi offers a larger choice of options, but in practice, the\n",
    "`graphviz/dot` layout offers the best way to visualise the transaction trees.\n",
    "\n",
    "yEd offers fewer layout choices, but arguably more of them are suited to\n",
    "transaction tree visualisation. In particular, two sets of layouts are most\n",
    "helpful:\n",
    "\n",
    "* `hierarchical`\n",
    "* `series-parallel`\n",
    "\n",
    "and\n",
    "\n",
    "* `circular`\n",
    "* `tree-balloon`\n",
    "\n",
    "The first two are similar to Gephi's `graphviz/dot` layout, and represent trees\n",
    "in the traditional fashion, which works well for relatively narrow, deep trees.\n",
    "The second two work better for broad, shallow trees. In the samples we have\n",
    "seen, transaction trees can take either \"shape\".\n",
    "\n",
    "Even with a sample of just 20 transaction trees, it can be difficult to\n",
    "interpret the graph visualisations. This is because some transaction nodes are\n",
    "*degenerate* in the sense that relatively few fields have values assigned to\n",
    "them. When such transaction nodes are shared between separate transaction\n",
    "trees, this adds complexity to the graph because the corresponding transaction\n",
    "trees overlap each other.\n",
    "\n",
    "Thus there is a visualisation dilemma: visualise single trees (thereby losing\n",
    "some information and hiding some of the complexity), or visualise the sample of\n",
    "trees (keeping all the information but making interpretation more difficult).\n",
    "The latter is more realistic but the resulting \"tangle\" of transaction trees\n",
    "looks like overgrown woodland rather than a forestry plantation.\n",
    "\n",
    "The solution was to show transaction trees in context, but to highlight the\n",
    "edges belonging to a specified tree. The transaction tree we wish to highlight\n",
    "is displayed with black edges but the edges of other trees are light grey.\n",
    "\n",
    "To achieve this type of labeling, it was necessary to enhance the neo4j data\n",
    "model as it applies to the relationships in the graph. In particular, it was\n",
    "necessary determine a (combination) of identifiers that is unique per\n",
    "transaction tree. Since each tree is *rooted* in a single `U` node, it makes\n",
    "sense to label the tree according to an identifier based on the fields (Neo4j\n",
    "properties) in its root `U` node.  While the concatenation of all field values\n",
    "in that node serves as a possible tree identifier, it is long and cumbersome to\n",
    "use. A *sufficient subset* comprises the `DcxId` and `TreeId` fields. These\n",
    "attributes were added to all the edges in the transaction tree, and were\n",
    "assigned so that every edge \"under\" the root `U` node has the same values of\n",
    "`DcxId` and `TreeId` as the root node.\n",
    "\n",
    "There were some technical issues to overcome, in the sense that yEd tended to\n",
    "\"drop\" the value of the `DcxId` field from the edges when exporting the diagram\n",
    "as graphml.  The `TreeId` field did not have this problem, as it was an\n",
    "integer. It appeared that yEd might choose to do so because of the presence of\n",
    "non-alphanumeric characters (such as \"$\" and \"#\") in the `DcxId` strings.\n",
    "Wrapping the `DcxId` values in 'CDATA[...]` protected them from the first stage\n",
    "of yEd exports, but not from the second. Therefore, it was decided to derive a\n",
    "numeric *surrogate* key for transaction trees, and to add this field, with the\n",
    "Cormel-derived `DcxId` and `TreeId` fields in the transaction tree edges.\n",
    "\n",
    "A further technical issue was caused by the fact that some transaction tree\n",
    "edges, and not just transaction nodes, are \"shared\" between transaction trees.\n",
    "Such shared edges occur when a shared transaction node is connected to another\n",
    "shared transaction node in the same transaction tree.  While shared edges share\n",
    "the same start and end nodes, they have different property values and hence\n",
    "neo4j sees them as different edges. This complication has two effects:\n",
    "\n",
    "1. Gephi ignores the edge property values and focuses just on the start and end\n",
    "nodes of each edge. Thus it sees \"shared\" edges as repeated edges, and displays\n",
    "a single edge instead whose weight (hence line width) is the sum of the weights\n",
    "of the individual edges sharing those start and end nodes. yEd notices the\n",
    "differing property values between the \"shared\" edges and so does not do\n",
    "anything special with such edges. It was decided that Gephi's interpretation\n",
    "was unwelcome, because it drew excessive attention to such shared edges.\n",
    "Consequently, a processing stage was added while populating the neo4j database\n",
    "to create a table whose columns were a) the `fromNodeId`, b) the `toNodeId` and\n",
    "c), the corresponding list of `edgeId`s. In most cases, that list contained a\n",
    "single element, but where \"shared\" edges occurred, two or more `edgeId`s could\n",
    "be found. This was added as a further neo4j edge property (`Rel_TreeList`)\n",
    "which is exported to graphml as `edgeTreeList`. From the `edgeTreeList`\n",
    "property for each edge, a derived `card` (short for \"cardinality\") is computed\n",
    "from the number of neo4j relationships sharing that edge.  The exporter for\n",
    "Gephi was modified so that the edge weight was assigned `1/card` instead of `1`\n",
    "as before.\n",
    "\n",
    "2. A race condition is introduced by the presence of potentially contrasting\n",
    "line colours for the \"same\" edge. That is, if the highlighted transaction tree\n",
    "\"shares\" an edge with one or more standard transaction trees, the colour of\n",
    "that edge depends on which tree has the highest surrogate key value, and not on\n",
    "whether the transaction tree is highlighted or not. The solution was not to\n",
    "change the colour, but to change the line width of all non-selected transaction\n",
    "tree edges in that set of shared edges, provided the selected tree is one of them.\n",
    "Since the line width was set to zero, it becomes invisible, and so cannot\n",
    "overwrite the edge if it was already drawn as a highlighted edge.\n",
    "\n",
    "#### Summary of the graphml processing in Gephi and yEd\n",
    "\n",
    "When the `output/graphml/sample20gephi.graphml` or\n",
    "`output/graphml/sample20gephi.graphml` has been generated as described earlier,\n",
    "it is possible to upload into the relevant application (Gephi or yEd,\n",
    "respectively).  After the layout algorithm has been applied, it is the possible\n",
    "to export the resulting graph (with position information) to files such as:\n",
    "\n",
    "    output/graphml/sample20gephi_dot.graphml\n",
    "    output/graphml/sample20yed_circular.graphml\n",
    "    output/graphml/sample20yed_hierarchical.graphml\n",
    "    output/graphml/sample20yed_seriesParallel.graphml\n",
    "    output/graphml/sample20yed_treeBalloon.graphml\n",
    "\n",
    "Such files show all transaction trees together. Some trees overlap, making\n",
    "interpretation difficult, as described earlier.\n",
    "\n",
    "To highlight each of the transaction trees, for each of the yEd-based layouts\n",
    "(\"circular\", \"hierarchical\", \"series-parallel\" and \"tree-balloon\"), the\n",
    "following script is convenient:\n",
    "\n",
    "    script/highlightTypesRangeOfTrees.sh 20\n",
    "\n",
    "where it has been assumed that the input file names follow the pattern above.\n",
    "The resulting graphml files take the form:\n",
    "\n",
    "    output/graphml/sample${numTrees}${app}_${layout}_hl${i}.graphml\n",
    "\n",
    "with examples such as\n",
    "\n",
    "    output/graphml/sample20yed_circular_hl01.graphml\n",
    "    ...\n",
    "    output/graphml/sample20yed_circular_hl20.graphml\n",
    "    output/graphml/sample20yed_hierarchical_hl01.graphml\n",
    "    ...\n",
    "    output/graphml/sample20yed_hierarchical_hl20.graphml\n",
    "    output/graphml/sample20yed_seriesParallel_hl01.graphml\n",
    "    ...\n",
    "    output/graphml/sample20yed_seriesParallel_hl20.graphml\n",
    "    output/graphml/sample20yed_treeBalloon_hl01.graphml\n",
    "    ...\n",
    "    output/graphml/sample20yed_treeBalloon_hl20.graphml\n",
    "\n",
    "For publication purposes, it is necessary to convert the 20\\*4 = 80 such files\n",
    "from graphml to pdf.  This is achieved by opening each file in yEd and\n",
    "exporting it (in PDF format) to a file with the same name but a pdf extension.\n",
    "Unfortunately this is a manual operation: yEd is a freeware graph viewer and\n",
    "its parent company (yWorks GmBH) sells a suite of software that can be used to\n",
    "automate such processes.\n",
    "\n",
    "For including the PDF graph \"pictures\", it is more convenient to trim\n",
    "unnecessary whitespace that had been added by yEd so that the graphs fit in an\n",
    "A4 page.This can be achieved using\n",
    "\n",
    "    script/cropPdfs.sh 20\n",
    "\n",
    "which defaults to PDF filenames with the following pattern:\n",
    "\n",
    "    output/graphml/sample${numTrees}${app}_${layout}_hl${i}.graphml\n",
    "\n",
    "Optionally, it is possible to combine these PDF files by yEd layout type, using\n",
    "\n",
    "    script/assemblePdfs.sh\n",
    "\n",
    "giving\n",
    "\n",
    "    output/pdf/sample20yed_circular_hl.pdf\n",
    "    output/pdf/sample20yed_hierarchical_hl.pdf\n",
    "    output/pdf/sample20yed_seriesParallel_hl.pdf\n",
    "    output/pdf/sample20yed_treeBalloon_hl.pdf\n",
    "\n",
    "It is then possible to open such files in PDF viewer and compare different\n",
    "transaction trees in a more convenient fashion, e.g., by viewing them as \"animations\"\n",
    "by advancing the page: human visual perception is relatively good at noticing\n",
    "differences between successive \"frames\" (graph plots).\n",
    "\n",
    "## Summary and Next Steps\n",
    "\n",
    "Figure 2 below is a summary of the processing pipeline described above.\n",
    "\n",
    "![Figure 1: Overview of the processing pipeline.](img/pipeline-CROPPED.png){height=9cm}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "The next steps are\n",
       "\n",
       "1.  get some of the latest CorMel data - I need to make some changes to my\n",
       "code to load the extra fields that have been added to the Avro schema, so\n",
       "it would be good to get that done soon;\n",
       "\n",
       "2.  find how to label individual transaction trees according to whether\n",
       "they have succeeded or failed. Joel has run some queries on the Transaction\n",
       "status using the ElasticSearch web front end and provided some example data,\n",
       "in JSON format to generate understanding;\n",
       "\n",
       "3.  We need to be able to generate both CorMel and ElasticSearch data\n",
       "that are cross-referenceable by `DcxId` and possibly other fields. In practice,\n",
       "since the log data that ElasticSearch queries is never more than a few days old,\n",
       "we need the CorMel extracts to restart.\n",
       "\n",
       "4.  try to develop a model to predict whether a transaction tree has failed\n",
       "or not, based on features derived from such transaction trees.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "with open('markdown/nextSteps.md', 'r') as fh:\n",
    "    content = fh.read()\n",
    "\n",
    "display(Markdown(content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
